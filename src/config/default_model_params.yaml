experiment_params:
  num_seeds: 5
  num_episodes: 20
  trials_per_episode: 100
  agents_per_condition: 50
  hrl_exp_save_path: logs/hrl

healthy:
  policy_params:
    learning_rate: 0.12          # balanced learning rate
    gamma: 0.96                  # strong long-term weighting
    epsilon: 0.65                # initial exploration bias
    epsilon_decay: 0.996         # gradual shift toward exploitation
    epsilon_min: 0.05            # minimum exploration threshold
    epsilon_max: 1.0             # maximum exploration threshold
    temperature: 0.9             # standard stochasticity, with some bias for high-value actions
  dopamine_modulation:
    tonic_drift: 0.03            # slight tonic dopamine adjustment
    scaling: 1.0                 # Slightly amplified RPE signal (healthy individuals want rewards)
    sensitivity: 0.9             # balanced reward/punishment weighting

overactive:
  policy_params:
    learning_rate: 0.45          # very aggressive learning
    gamma: 0.1                   # nearly no regard for future reward
    epsilon: 0.25                # almost purely exploitative
    epsilon_decay: 0.999         # much slower decay
    epsilon_min: 0.005           # minimal exploration
    epsilon_max: 0.6             # lower overall exploration, still possible to explore
    temperature: 0.6             # increased determinism, with slight bias for high-value actions
  dopamine_modulation:
    tonic_drift: 0.02            # mild tonic dopamine adjustment
    scaling: 1.8                 # enhanced RPE amplitude
    sensitivity: 0.4             # punishments down-weighted

depleted:
  policy_params:
    learning_rate: 0.08          # much slower learning rate
    gamma: 0.95                  # strong future bias, leading to indecision
    epsilon: 0.9                 # very high exploration, weak exploitation
    epsilon_decay: 0.998         # very slow decay, can't settle
    epsilon_min: 0.75            # remains indecisive
    epsilon_max: 1.0             # full exploration potential
    temperature: 2.0             # high stochasticity
  dopamine_modulation:
    tonic_drift: 0.12            # stronger tonic dopamine adjustment
    scaling: 0.3                 # severely dampened RPE signal
    sensitivity: 3.2             # punishments hit much harder, leading to catastrophic demotivation
